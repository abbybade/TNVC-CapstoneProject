{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sqlalchemy.sql import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Directory\n",
    "dir ='Copy of Master Dashboard.xlsx'\n",
    "\n",
    "# Load all sheets into a dictionary of DataFrames\n",
    "sheets = pd.read_excel(dir, sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Transform Tables/Sheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transform Companies Table\n",
    "companies_df = sheets['companies']\n",
    "\n",
    "# Rename columns to match the database schema\n",
    "companies_df.rename(columns={\n",
    "    'Id': 'company_id',\n",
    "    'Company': 'company',\n",
    "    'Industry': 'industry',\n",
    "    'Region': 'region',\n",
    "    '1st Participation Year': 'first_participation_year',\n",
    "    'Multiple Year': 'multiple_year',\n",
    "    'Best Result': 'best_result',\n",
    "    'Initial Funds': 'initial_funds',\n",
    "    'Initial Employees': 'initial_employees',\n",
    "    'TAMU Affiliated': 'tamu_affiliated',\n",
    "    'Spinout': 'spinout',\n",
    "    'College/Entity': 'college_entity',\n",
    "    'Sponsor TAMU research?': 'sponsor_tamu_research',\n",
    "    'Details': 'details'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert boolean-like columns ('x' vs empty) to proper boolean values\n",
    "companies_df['tamu_affiliated'] = companies_df['tamu_affiliated'].replace({'x': True, '': False, None: False}).astype(bool)\n",
    "companies_df['spinout'] = companies_df['spinout'].replace({'x': True, '': False, None: False}).astype(bool)\n",
    "companies_df['sponsor_tamu_research'] = companies_df['sponsor_tamu_research'].replace({'x': True, '': False, None: False}).astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Transform Summary Table\n",
    "summary_df = sheets['summary']\n",
    "\n",
    "summary_df.rename(columns={\n",
    "    'Company': 'company',\n",
    "    'TAMUS Affiliated': 'tamus_affiliated',\n",
    "    'TAMUS Spinout': 'tamus_spinout',\n",
    "    'Best Result': 'best_result',\n",
    "    'First Part. Year': 'first_part_year',\n",
    "    'Initial Funds': 'initial_funds',\n",
    "    'Last Known Status': 'last_known_status',\n",
    "    'tnvc_prize_cash': 'tnvc_prize_cash',\n",
    "    'spons_research': 'spons_research',\n",
    "    'TAMUS_spons_res': 'tamus_spons_res',\n",
    "    'dilutive': 'dilutive',\n",
    "    'non-dilutive': 'non_dilutive',\n",
    "    'detail total': 'detail_total',\n",
    "    'total-nodetail': 'total_nodetail',\n",
    "    'Grand Total': 'grand_total',\n",
    "    'TAMUS Funds': 'tamus_funds',\n",
    "    'TEES Funds': 'tees_funds',\n",
    "    'Employees': 'employees',\n",
    "    'Lic Fees/Roys.': 'lic_fees_roys'\n",
    "}, inplace=True)\n",
    "\n",
    "summary_df = summary_df.loc[:, ~summary_df.columns.str.contains('^Unnamed')]\n",
    "summary_df.loc[:, 'tamus_affiliated'] = summary_df['tamus_affiliated'].replace({'x': True, '': False}).astype(bool)\n",
    "summary_df.loc[:, 'tamus_spinout'] = summary_df['tamus_spinout'].replace({'x': True, '': False}).astype(bool)\n",
    "financial_columns = [\n",
    "    'initial_funds', 'tnvc_prize_cash', 'spons_research', \n",
    "    'tamus_spons_res', 'dilutive', 'non_dilutive', \n",
    "    'detail_total', 'total_nodetail', 'grand_total', \n",
    "    'tamus_funds', 'tees_funds', \n",
    "]\n",
    "for col in financial_columns:\n",
    "    summary_df.loc[:, col] = (\n",
    "        summary_df[col]\n",
    "        .replace({'\\$': '', ',': ''}, regex=True)  \n",
    "        .replace({'': None})  \n",
    "        .astype(float)  \n",
    "    )\n",
    "\n",
    "\n",
    "# 3. Transform Prizes Table\n",
    "prizes_df = sheets['prizes']\n",
    "\n",
    "# Rename columns\n",
    "prizes_df.rename(columns={\n",
    "    'Company': 'company',\n",
    "    'Type': 'type',\n",
    "    'auxiliary column (DONT DELETE)': 'auxiliary_column',\n",
    "    'Amount': 'amount',\n",
    "    'Year': 'year',\n",
    "    'Description': 'description'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert Amount to numeric\n",
    "prizes_df['amount'] = prizes_df['amount'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "#prizes_df.head(5)\n",
    "\n",
    "# 4. Transform SR Table\n",
    "sr_df = sheets['sr']\n",
    "\n",
    "# Rename columns\n",
    "sr_df.rename(columns={\n",
    "    'Company Name': 'company_name',\n",
    "    'TAMUS Company': 'tamus_company',\n",
    "    'Buss w TAMUS?': 'buss_w_tamus',\n",
    "    'Value': 'value',\n",
    "    'Source': 'source',\n",
    "    'Added By': 'added_by',\n",
    "    'Date': 'date',\n",
    "    'Comments': 'comments'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert boolean columns\n",
    "sr_df['tamus_company'] = sr_df['tamus_company'].fillna(0).astype(bool)\n",
    "sr_df['buss_w_tamus'] = sr_df['buss_w_tamus'].fillna(0).astype(bool)\n",
    "\n",
    "# Convert Value to numeric\n",
    "sr_df['value'] = sr_df['value'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Convert Date to datetime\n",
    "sr_df['date'] = pd.to_datetime(sr_df['date'], errors='coerce')\n",
    "\n",
    "#sr_df.head(5)\n",
    "\n",
    "\n",
    "# 5. Transform TAMUSR Table\n",
    "tamusr_df = sheets['tamusr']\n",
    "\n",
    "# Rename columns\n",
    "tamusr_df.rename(columns={\n",
    "    'Company': 'company',\n",
    "    'TAMU Dept': 'tamu_dept',\n",
    "    'Contract Value': 'contract_value',\n",
    "    'ORIGINAL DATA - COMPANY': 'original_data_company',\n",
    "    'ORIGINAL DATA - TAMU DEPARTMENT': 'original_data_tamu_department'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert Contract Value to numeric\n",
    "tamusr_df['contract_value'] = tamusr_df['contract_value'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# 6. Transform licfr Table\n",
    "try:\n",
    "    # Load the licfr sheet and remove irrelevant rows if any\n",
    "    licfr_df = sheets['licfr']\n",
    "    licfr_df.columns = licfr_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match database schema\n",
    "    licfr_df = licfr_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        'TAMUS Company': 'tamus_company',\n",
    "        'TEES Company': 'tees_company',\n",
    "        'Research Institution': 'research_institution',\n",
    "        'TEES Res. Inst.': 'tees_res_institution',\n",
    "        'TAMUS Res. Inst.': 'tamus_res_institution',\n",
    "        'TAMUS/TEES Res Ins.': 'tamus_tees_res_institution',\n",
    "        'Aux. Column (DO NOT DELETE)': 'aux_column',\n",
    "        'Value': 'value',\n",
    "        'Source': 'source',\n",
    "        'Added by': 'added_by',\n",
    "        'Date': 'date',\n",
    "        'Comments': 'comments'\n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    licfr_df = licfr_df[licfr_df['company'].notna()]\n",
    "\n",
    "    # Ensure correct boolean conversion: explicitly check for \"x\"\n",
    "    bool_columns = ['tamus_company', 'tees_company', 'tees_res_institution', \n",
    "                    'tamus_res_institution', 'tamus_tees_res_institution']\n",
    "    \n",
    "    for col in bool_columns:\n",
    "        licfr_df[col] = licfr_df[col].apply(lambda x: True if str(x).strip().lower() == 'x' else False)\n",
    "\n",
    "    # Convert `value` column to numeric, handling non-numeric values\n",
    "    licfr_df['value'] = pd.to_numeric(licfr_df['value'].replace({'\\$': '', ',': ''}, regex=True), errors='coerce')\n",
    "\n",
    "    # Convert `date` column to datetime\n",
    "    licfr_df['date'] = pd.to_datetime(licfr_df['date'], errors='coerce')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error transforming licfr table: {e}\")\n",
    "\n",
    "\n",
    "# 7. Transform funds Table\n",
    "\n",
    "try:\n",
    "    # Load the funds sheet\n",
    "    funds_df = sheets['funds']\n",
    "    funds_df.columns = funds_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match the database schema\n",
    "    funds_df = funds_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        'Type': 'type',\n",
    "        'Aux. Column (DO NOT DELETE)': 'aux_column',\n",
    "        'Value': 'value',\n",
    "        'Date Added': 'date_added',\n",
    "        'Added By?': 'added_by',\n",
    "        'Source': 'source',\n",
    "        'Comments': 'comments',\n",
    "        'Verified': 'verified'  \n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    funds_df = funds_df[funds_df['company'].notna()]\n",
    "\n",
    "    # Convert `value` column to numeric, handling any currency symbols or commas\n",
    "    funds_df['value'] = pd.to_numeric(funds_df['value'].replace({'\\$': '', ',': ''}, regex=True), errors='coerce')\n",
    "\n",
    "    # Convert `date_added` column to datetime\n",
    "    funds_df['date_added'] = pd.to_datetime(funds_df['date_added'], errors='coerce')\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine('postgresql://postgres:1212@localhost:1212/TNVC')  # Update with actual credentials\n",
    "\n",
    "    # Fetch company IDs from the companies table\n",
    "    company_ids = pd.read_sql(\"SELECT company_id, company FROM etl.companies\", engine)\n",
    "\n",
    "    # Merge to get company_id\n",
    "    funds_df = funds_df.merge(company_ids, on='company', how='left')\n",
    "\n",
    "    # Check for any companies that didn't match\n",
    "    unmatched = funds_df[funds_df['company_id'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"Warning: The following companies didn't match with the companies table:\")\n",
    "        print(unmatched['company'].unique())\n",
    "\n",
    "    # Drop rows with no company_id match to maintain referential integrity\n",
    "    funds_df = funds_df.dropna(subset=['company_id'])\n",
    "\n",
    "    # Reorder columns to match table structure\n",
    "    funds_df = funds_df[['company_id', 'company', 'type', 'aux_column', 'value', 'date_added', 'added_by', 'source', 'comments', 'verified']]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in ET step for funds table: {e}\")\n",
    "\n",
    "# 8. Transform status Table\n",
    "\n",
    "try:\n",
    "    # Load the status sheet\n",
    "    status_df = sheets['status']\n",
    "    status_df.columns = status_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match the database schema\n",
    "    status_df = status_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        'Status Record': 'status_record',\n",
    "        'Date': 'date',\n",
    "        'Added By?': 'added_by',\n",
    "        'Source': 'source',\n",
    "        'Comments': 'comments'\n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    status_df = status_df[status_df['company'].notna()]\n",
    "\n",
    "    # Convert `date` column to datetime\n",
    "    status_df['date'] = pd.to_datetime(status_df['date'], errors='coerce')\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine('postgresql://postgres:1212@localhost:1212/TNVC')  # Update with actual credentials\n",
    "\n",
    "    # Fetch company IDs from the companies table\n",
    "    company_ids = pd.read_sql(\"SELECT company_id, company FROM etl.companies\", engine)\n",
    "\n",
    "    # Merge to get company_id\n",
    "    status_df = status_df.merge(company_ids, on='company', how='left')\n",
    "\n",
    "    # Check for any companies that didn't match\n",
    "    unmatched = status_df[status_df['company_id'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"Warning: The following companies didn't match with the companies table:\")\n",
    "        print(unmatched['company'].unique())\n",
    "        print(f\"Number of unmatched records: {len(unmatched)}\")\n",
    "\n",
    "    # Instead of dropping, we'll keep all records and set company_id to None for unmatched companies\n",
    "    status_df['company_id'] = status_df['company_id'].astype('Int64')  # This allows for NULL values in integer column\n",
    "\n",
    "    # Reorder columns to match table structure\n",
    "    status_df = status_df[['company_id', 'company', 'status_record', 'date', 'added_by', 'source', 'comments']]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in ET step for status table: {e}\")\n",
    "\n",
    "# 9 Transform Employee Table \n",
    "\n",
    "try:\n",
    "    # Load the employee sheet\n",
    "    employee_df = sheets['employees']\n",
    "    employee_df.columns = employee_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match the database schema\n",
    "    employee_df = employee_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        'Value': 'value',\n",
    "        'Date': 'date',\n",
    "        'Added By?': 'added_by',\n",
    "        'Source': 'source',\n",
    "        'Comments': 'comments'\n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    employee_df = employee_df[employee_df['company'].notna()]\n",
    "\n",
    "    # Convert `value` column to integer\n",
    "    employee_df['value'] = pd.to_numeric(employee_df['value'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Convert `date` column to datetime\n",
    "    employee_df['date'] = pd.to_datetime(employee_df['date'], errors='coerce')\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine('postgresql://postgres:1212@localhost:1212/TNVC')  # Update with actual credentials\n",
    "\n",
    "    # Fetch company IDs from the companies table\n",
    "    company_ids = pd.read_sql(\"SELECT company_id, company FROM etl.companies\", engine)\n",
    "\n",
    "    # Merge to get company_id\n",
    "    employee_df = employee_df.merge(company_ids, on='company', how='left')\n",
    "\n",
    "    # Check for any companies that didn't match\n",
    "    unmatched = employee_df[employee_df['company_id'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"Warning: The following companies didn't match with the companies table:\")\n",
    "        print(unmatched['company'].unique())\n",
    "        print(f\"Number of unmatched records: {len(unmatched)}\")\n",
    "\n",
    "    # Keep all records, including those without a matching company_id\n",
    "    employee_df['company_id'] = employee_df['company_id'].astype('Int64')  # This allows for NULL values in integer column\n",
    "\n",
    "    # Reorder columns to match table structure\n",
    "    employee_df = employee_df[['company_id', 'company', 'value', 'date', 'added_by', 'source', 'comments']]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in ET step for employee table: {e}\")\n",
    "\n",
    "\n",
    "# 10 Transform contacts Table\n",
    "try:\n",
    "    # Load the contacts sheet\n",
    "    contacts_df = sheets['contacts']\n",
    "    contacts_df.columns = contacts_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match the database schema\n",
    "    contacts_df = contacts_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        'First Name': 'first_name',\n",
    "        'Last Name': 'last_name',\n",
    "        'Entry': 'entry',\n",
    "        'Comments': 'comments',\n",
    "        '2019 Survey': 'survey_2019',\n",
    "        'Company Last Status': 'company_last_status',\n",
    "        '1st Participation Year': 'first_participation_year',\n",
    "        'Multiple Year': 'multiple_year',\n",
    "        'Best Result': 'best_result'\n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    contacts_df = contacts_df[contacts_df['company'].notna()]\n",
    "\n",
    "    # Convert '2019 Survey' to boolean\n",
    "    contacts_df['survey_2019'] = contacts_df['survey_2019'].map({'x': True, '': False})\n",
    "\n",
    "    # Convert 'Company Last Status' to numeric\n",
    "    contacts_df['company_last_status'] = pd.to_numeric(contacts_df['company_last_status'], errors='coerce')\n",
    "\n",
    "    # Convert '1st Participation Year' to integer\n",
    "    contacts_df['first_participation_year'] = pd.to_numeric(contacts_df['first_participation_year'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "# Convert 'multiple_year' to integer\n",
    "    contacts_df['multiple_year'] = pd.to_numeric(contacts_df['multiple_year'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine('postgresql://postgres:1212@localhost:1212/TNVC')  # Update with actual credentials\n",
    "\n",
    "    # Fetch company IDs from the companies table\n",
    "    company_ids = pd.read_sql(\"SELECT company_id, company FROM etl.companies\", engine)\n",
    "\n",
    "    # Merge to get company_id\n",
    "    contacts_df = contacts_df.merge(company_ids, on='company', how='left')\n",
    "\n",
    "    # Check for any companies that didn't match\n",
    "    unmatched = contacts_df[contacts_df['company_id'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"Warning: The following companies didn't match with the companies table:\")\n",
    "        print(unmatched['company'].unique())\n",
    "        print(f\"Number of unmatched records: {len(unmatched)}\")\n",
    "\n",
    "    # Keep all records, including those without a matching company_id\n",
    "    contacts_df['company_id'] = contacts_df['company_id'].astype('Int64')  # This allows for NULL values in integer column\n",
    "\n",
    "    # Reorder columns to match table structure\n",
    "    contacts_df = contacts_df[['company_id', 'company', 'first_name', 'last_name', 'entry', 'comments', 'survey_2019', 'company_last_status', 'first_participation_year', 'multiple_year', 'best_result']]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in ET step for contacts table: {e}\")\n",
    "\n",
    "\n",
    "# 11 Transform industry_region table \n",
    "try:\n",
    "    # Load the industry_region sheet\n",
    "    industry_region_df = sheets['Industry & Region']\n",
    "    industry_region_df.columns = industry_region_df.columns.str.strip()  # Remove any leading/trailing spaces\n",
    "\n",
    "    # Rename columns to match the database schema\n",
    "    industry_region_df = industry_region_df.rename(columns={\n",
    "        'Company': 'company',\n",
    "        '1st Participation Year': 'first_participation_year',\n",
    "        'Application Category': 'application_category',\n",
    "        'Sub Category': 'sub_category',\n",
    "        'Flight Room': 'flight_room',\n",
    "        'Final Industry - our terms': 'final_industry',\n",
    "        'Region': 'region'\n",
    "    })\n",
    "\n",
    "    # Filter out rows with missing 'company' values\n",
    "    industry_region_df = industry_region_df[industry_region_df['company'].notna()]\n",
    "\n",
    "    # Convert 'first_participation_year' to integer\n",
    "    industry_region_df['first_participation_year'] = pd.to_numeric(industry_region_df['first_participation_year'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine('postgresql://postgres:1212@localhost:1212/TNVC')  # Update with actual credentials\n",
    "\n",
    "    # Fetch company IDs from the companies table\n",
    "    company_ids = pd.read_sql(\"SELECT company_id, company FROM etl.companies\", engine)\n",
    "\n",
    "    # Merge to get company_id\n",
    "    industry_region_df = industry_region_df.merge(company_ids, on='company', how='left')\n",
    "\n",
    "    # Check for any companies that didn't match\n",
    "    unmatched = industry_region_df[industry_region_df['company_id'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"Warning: The following companies didn't match with the companies table:\")\n",
    "        print(unmatched['company'].unique())\n",
    "        print(f\"Number of unmatched records: {len(unmatched)}\")\n",
    "\n",
    "    # Keep all records, including those without a matching company_id\n",
    "    industry_region_df['company_id'] = industry_region_df['company_id'].astype('Int64')  # This allows for NULL values in integer column\n",
    "\n",
    "    # Reorder columns to match table structure\n",
    "    industry_region_df = industry_region_df[['company_id', 'company', 'first_participation_year', 'application_category', 'sub_category', 'flight_room', 'final_industry', 'region']]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in ET step for industry_region table: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables into TNVC DB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "DATABASE_URI = 'postgresql://postgres:1212@localhost:1212/TNVC'\n",
    "engine = create_engine(DATABASE_URI)\n",
    "\n",
    "# Truncate table function \n",
    "def truncate_table(engine, table_name, schema='etl'):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(f\"TRUNCATE TABLE {schema}.{table_name} RESTART IDENTITY CASCADE\"))\n",
    "            print(f\"Table '{schema}.{table_name}' truncated successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error truncating table '{schema}.{table_name}': {e}\")\n",
    "truncate_table(engine, 'companies', schema='etl')\n",
    "\n",
    "# Insert the companies table\n",
    "companies_df.to_sql(\n",
    "    name='companies',\n",
    "    con=engine,\n",
    "    schema='etl',\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Function to load all tables\n",
    "def load_all_tables(tables, schema='etl'):\n",
    "    for table_name, df in tables.items():\n",
    "        try:\n",
    "            if table_name == 'companies':\n",
    "                # Truncate companies table before loading\n",
    "                truncate_table(engine, table_name, schema)\n",
    "                if_exists = 'append'  # Append after truncating\n",
    "            else:\n",
    "                if_exists = 'replace'  # Replace other tables\n",
    "                \n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                schema=schema,\n",
    "                if_exists=if_exists,\n",
    "                index=False  # Do not write the DataFrame index\n",
    "            )\n",
    "            print(f\"Table '{schema}.{table_name}' loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading table '{schema}.{table_name}': {e}\")\n",
    "\n",
    "# Dictionary of tables to load\n",
    "tables = {\n",
    "    'companies': companies_df,\n",
    "    'summary': summary_df,\n",
    "    'prizes': prizes_df,\n",
    "    'sr': sr_df,\n",
    "    'tamusr': tamusr_df,\n",
    "    'licfr': licfr_df,\n",
    "    'funds': funds_df,\n",
    "    'status': status_df,\n",
    "    'employees': employee_df,\n",
    "    'contacts': contacts_df,\n",
    "    'industry_region': industry_region_df\n",
    "}\n",
    "\n",
    "# Load all tables\n",
    "load_all_tables(tables)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
